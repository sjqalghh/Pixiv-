from DrissionPage import Chromium, ChromiumOptions
import requests
import re
import os
import time
import random
import sys
import threading
import keyboard  # è·¨å¹³å°æŒ‰é”®ç›‘å¬åº“

# ========== é…ç½® ==========
SAVE_ROOT = r"D:\pixiv"   # ä¿å­˜æ ¹ç›®å½•
REQUEST_TIMEOUT = 15      # è¯·æ±‚è¶…æ—¶ï¼ˆç§’ï¼‰
MIN_DELAY, MAX_DELAY = 0, 0  # å»æ‰ä¸‹è½½ç­‰å¾…
PAUSE_KEY = 'space'       # ä½¿ç”¨ç©ºæ ¼é”®æš‚åœ/æ¢å¤

# ========== è¾…åŠ©å‡½æ•° ==========
def to_original_url(thumb_url: str) -> str:
    """æ ¹æ®ç¼©ç•¥å›¾ URL é‡ç»„ä¸º img-original çš„å¯èƒ½åŸå›¾ URLï¼ˆä¼˜å…ˆ .jpgï¼‰ã€‚"""
    if not thumb_url:
        return thumb_url
    m = re.search(r'https://i\.pximg\.net/.+?/(?:img-master|custom-thumb)/img/(.+?)_p0', thumb_url)
    if m:
        path = m.group(1)
        return f'https://i.pximg.net/img-original/img/{path}_p0.jpg'
    m2 = re.search(r'https://i\.pximg\.net/c/.+?/img/(.+?)_p0', thumb_url)
    if m2:
        path = m2.group(1)
        return f'https://i.pximg.net/img-original/img/{path}_p0.jpg'
    m3 = re.search(r'/img/(.+?)_p0', thumb_url)
    if m3:
        path = m3.group(1)
        return f'https://i.pximg.net/img-original/img/{path}_p0.jpg'
    return thumb_url

def extract_author_name(alt_text: str) -> str:
    """ä» alt å±æ€§ä¸­æå–ä½œè€…åå­—ã€‚"""
    match = re.search(r"-\s*(.*?)çš„æ’ç”»$", alt_text)
    if match:
        return match.group(1).strip()
    return "æœªçŸ¥ä½œè€…"

def sanitize_filename(name: str) -> str:
    """æ¸…é™¤Windowsæ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦"""
    return re.sub(r'[\\/:*?"<>|]', '_', name)

def download_image_silent(url: str, filename: str, headers: dict) -> bool:
    """é»˜è®¤ä¸‹è½½jpgï¼Œå¤±è´¥é™é»˜æ”¹ä¸ºpngå†å°è¯•"""
    try:
        r = requests.get(url, headers=headers, timeout=REQUEST_TIMEOUT)
        if r.status_code == 200 and r.content:
            with open(filename, 'wb') as f:
                f.write(r.content)
            print(f"âœ… æˆåŠŸä¿å­˜ï¼š{filename}")
            return True
        if url.endswith('.jpg'):
            alt_url = url.replace('.jpg', '.png')
            r2 = requests.get(alt_url, headers=headers, timeout=REQUEST_TIMEOUT)
            if r2.status_code == 200 and r2.content:
                with open(filename, 'wb') as f:
                    f.write(r2.content)
                print(f"âœ… æˆåŠŸä¿å­˜ï¼š{filename}")
                return True
    except Exception as e:
        print(f"âš ï¸ ä¸‹è½½å¼‚å¸¸ï¼š{e}")
        if url.endswith('.jpg'):
            try:
                alt_url = url.replace('.jpg', '.png')
                r2 = requests.get(alt_url, headers=headers, timeout=REQUEST_TIMEOUT)
                if r2.status_code == 200 and r2.content:
                    with open(filename, 'wb') as f:
                        f.write(r2.content)
                    print(f"âœ… æˆåŠŸä¿å­˜ï¼š{filename}")
                    return True
            except Exception:
                pass
    return False

def read_downloaded_images(file_path: str):
    """è¯»å–å·²ä¸‹è½½å›¾ç‰‡æ–‡ä»¶åˆ—è¡¨"""
    if os.path.exists(file_path):
        with open(file_path, 'r', encoding='utf-8') as f:
            return set(f.read().splitlines())
    return set()

def write_downloaded_image(file_path: str, image_path: str):
    """è®°å½•å·²ä¸‹è½½çš„å›¾ç‰‡åˆ°æ–‡ä»¶"""
    with open(file_path, 'a', encoding='utf-8') as f:
        f.write(image_path + '\n')

def is_image_downloaded(image_path: str, downloaded_images: set) -> bool:
    """æ£€æŸ¥å›¾ç‰‡æ˜¯å¦å·²ä¸‹è½½"""
    return image_path in downloaded_images

# ========== æš‚åœä¸æ¢å¤åŠŸèƒ½ ==========
is_paused = False

def pause_resume_listener():
    global is_paused
    while True:
        keyboard.wait(PAUSE_KEY)  # ç­‰å¾…æŒ‰ä¸‹ç©ºæ ¼é”®
        is_paused = not is_paused
        if is_paused:
            print("â¸ï¸ çˆ¬å–å·²æš‚åœï¼ŒæŒ‰ç©ºæ ¼é”®æ¢å¤...")
        else:
            print("â–¶ï¸ çˆ¬å–æ¢å¤...")
        time.sleep(0.5)  # é˜²æ­¢å¿«é€Ÿé‡å¤è§¦å‘

# ========== ä¸»ç¨‹åº ==========
def main():
    global is_paused
    tag_name = input("è¯·è¾“å…¥è¦çˆ¬å–çš„è§’è‰²åï¼ˆå¦‚ HuTaoã€Raidenã€Furina ç­‰ï¼‰ï¼š").strip()
    page_input = input("è¯·è¾“å…¥è¦çˆ¬å–çš„é¡µç ï¼ˆå•é¡µå¦‚ P=1ï¼Œè¡¨ç¤ºä»ç¬¬ä¸€é¡µå¼€å§‹ï¼‰ï¼š").strip()
    
    try:
        page_num = int(page_input.split('=')[-1].strip())
    except ValueError:
        print("è¾“å…¥é¡µç æ— æ•ˆ")
        return
    
    range_input = input(f"è¯·è¾“å…¥åœ¨ç¬¬ {page_num} é¡µçˆ¬å–çš„å›¾ç‰‡èŒƒå›´ï¼ˆä¾‹å¦‚ï¼š1-10ï¼Œè¡¨ç¤ºä»ç¬¬1å¼ åˆ°ç¬¬10å¼ ï¼‰ï¼š").strip()
    
    try:
        start, end = map(int, range_input.split('-'))
        if start <= 0 or end < start:
            print("è¾“å…¥çš„å›¾ç‰‡èŒƒå›´æ— æ•ˆ")
            return
    except ValueError:
        print("è¾“å…¥çš„å›¾ç‰‡èŒƒå›´æ ¼å¼ä¸æ­£ç¡®")
        return

    # åœ¨ç”¨æˆ·è¾“å…¥å®Œæˆå¹¶éªŒè¯åå¯åŠ¨æš‚åœ/æ¢å¤ç›‘å¬çº¿ç¨‹
    threading.Thread(target=pause_resume_listener, daemon=True).start()
    print(f"â„¹ï¸ æŒ‰ç©ºæ ¼é”®å¯æš‚åœ/æ¢å¤çˆ¬å–...")

    co = ChromiumOptions()
    co.headless(True)  # âœ… å¯ç”¨æ— å¤´æ¨¡å¼
    co.set_argument('--window-size=1920,1080')
    co.set_argument('--blink-settings=imagesEnabled=true')
    co.set_argument('--disable-blink-features=AutomationControlled')
    co.set_argument('--no-sandbox')
    co.set_argument('--disable-dev-shm-usage')
    co.set_local_port(9222)

    try:
        browser = Chromium(co)
    except Exception as e:
        print(f"æ— æ³•è¿æ¥ Chromiumï¼š{e}")
        return

    save_dir = os.path.join(SAVE_ROOT, tag_name)
    os.makedirs(save_dir, exist_ok=True)

    downloaded_images_file = os.path.join(save_dir, 'downloaded_images.txt')
    downloaded_images = read_downloaded_images(downloaded_images_file)

    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)',
        'Referer': 'https://www.pixiv.net/',
    }

    page_url = f"https://www.pixiv.net/tags/{tag_name}/illustrations?p={page_num}"
    print(f"\nğŸ”— æ­£åœ¨ä¸‹è½½ç¬¬ {page_num} é¡µï¼š{page_url}")

    try:
        tab = browser.new_tab(page_url)
        tab.wait(5)
    except Exception:
        print("è¾“å…¥é¡µæ•°ä¸å­˜åœ¨")
        try:
            tab.close()
        except Exception:
            pass
        return

    seen = set()
    seq = start
    found_any = False

    print("ğŸ”„ å¼€å§‹æ»šåŠ¨é¡µé¢ä»¥åŠ è½½æ‰€æœ‰å›¾ç‰‡...")
    for _ in range(5):
        tab.scroll.down(1200)
        time.sleep(random.uniform(1.0, 2.0))
        tab.scroll.right(1200)
        time.sleep(random.uniform(1.0, 2.0))

    for i in range(start, end + 1):
        try:
            img_ele = tab.ele(
                f'x:/html/body/div[1]/div/div[2]/div[5]/div[1]/div[3]/div[3]/section/div[2]/div[1]/ul/li[{i}]/div/div[1]/div/a/div[1]/div/img'
            )
        except Exception:
            img_ele = None

        if not img_ele:
            continue

        try:
            thumb_url = img_ele.attr('src') or img_ele.attr('data-src') or img_ele.attr('data-original') or ''
            if not thumb_url:
                # å¦‚æœ src ä¸ºç©ºï¼Œå¼ºåˆ¶è§¦å‘æ‡’åŠ è½½
                tab.run_js(f"""
                    var img = document.querySelectorAll('ul li')[{i-1}].querySelector('img');
                    if(img){{
                        var dsrc = img.getAttribute('data-src') || img.getAttribute('data-original');
                        if(dsrc) img.src = dsrc;
                    }}
                """)
                time.sleep(0.3)
                thumb_url = img_ele.attr('src') or img_ele.attr('data-src') or img_ele.attr('data-original') or ''
        except Exception:
            thumb_url = ''

        if not thumb_url:
            continue

        found_any = True

        if thumb_url.startswith('//'):
            thumb_url = 'https:' + thumb_url
        if thumb_url.startswith('/'):
            thumb_url = 'https://www.pixiv.net' + thumb_url

        alt_text = img_ele.attr('alt') or ""
        author_name = extract_author_name(alt_text)
        safe_author = sanitize_filename(author_name)

        orig_url = to_original_url(thumb_url)
        if not orig_url:
            continue

        if orig_url in seen or is_image_downloaded(orig_url, downloaded_images):
            continue
        seen.add(orig_url)

        filename = os.path.join(save_dir, f"{page_num}_{seq}_{safe_author}.jpg")
        seq += 1

        download_image_silent(orig_url, filename, headers)
        write_downloaded_image(downloaded_images_file, filename)

        while is_paused:
            time.sleep(0.5)

    try:
        tab.close()
    except Exception:
        pass

    if not found_any:
        print("è¾“å…¥é¡µæ•°ä¸å­˜åœ¨")
        return

    print("\nâœ… æŒ‡å®šå›¾ç‰‡èŒƒå›´å…¨éƒ¨å¤„ç†å®Œæ¯•ã€‚")

if __name__ == "__main__":
    main()